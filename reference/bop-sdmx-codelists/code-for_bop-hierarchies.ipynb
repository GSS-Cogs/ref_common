{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from gssutils import *\n",
    "from rdflib import Graph, Literal, RDF, URIRef\n",
    "import rdflib\n",
    "from rdflib.namespace import OWL, VOID, DCTERMS, RDF, RDFS, SKOS, XSD, FOAF, DC\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-b76a53e191f4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  are['Notation'][are['Label'] == 'Namibia'] = 'NA' # Namibia Notation comes through as a NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Notation</th>\n",
       "      <th>Parent Notation</th>\n",
       "      <th>Sort Priority</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not allocated/ unspecified</td>\n",
       "      <td>_X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not applicable</td>\n",
       "      <td>_Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMF (International Monetary Fund)</td>\n",
       "      <td>1C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WTO (World Trade Organisation)</td>\n",
       "      <td>1D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IBRD (International Bank for Reconstruction an...</td>\n",
       "      <td>1E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Label Notation  \\\n",
       "0                         Not allocated/ unspecified       _X   \n",
       "1                                     Not applicable       _Z   \n",
       "4                  IMF (International Monetary Fund)       1C   \n",
       "5                     WTO (World Trade Organisation)       1D   \n",
       "6  IBRD (International Bank for Reconstruction an...       1E   \n",
       "\n",
       "   Parent Notation  Sort Priority Description  \n",
       "0              NaN              1         NaN  \n",
       "1              NaN              2         NaN  \n",
       "4              NaN              5         NaN  \n",
       "5              NaN              6         NaN  \n",
       "6              NaN              7         NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "are = pd.read_csv('ref_common/reference/codelists/cl-area.csv')\n",
    "are['Notation'][are['Label'] == 'Namibia'] = 'NA' # Namibia Notation comes through as a NaN\n",
    "are2 = are[are['Description'].notnull()]\n",
    "are3 = are[are['Description'].isna()]\n",
    "are3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Persian Gulf Economies (CDIS),S35E,,718,S35E = BH + IQ + IR + KW + OM + QA + SA + AE + A35E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_thing_equals_other_things(descr, lab):\n",
    "    #### Example = 4AA=4B+4C+4D+4E+4G+4H+4I+4J+4R+4T+4U+4V+4S\n",
    "    meth_dat = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "    s1 = descr.split('=', 1) # Split into left side of = sign and right\n",
    "    s2 = s1[1].split('+')    # split the right side by +\n",
    "    s1 = s1[0]\n",
    "    for r in s2:\n",
    "        meth_dat = pd.concat([meth_dat, pd.DataFrame({'Narrower':[r.strip()], 'Main':[s1.strip()], 'Main Label':[lab]})], sort=False)\n",
    "    return meth_dat\n",
    "\n",
    "\n",
    "def one_equals_others_plus_some_minus_some(descr, lab):\n",
    "    #### Example = B5 = I8 + (BG + CZ + DK + GB + HR + HU + PL + RO + SE+ 4A + B09) -U29\n",
    "    meth_dat = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "    s1 = descr.split('-', 1) \n",
    "    s1 = s1[0].split('=', 1)\n",
    "    s1[1] = s1[1].replace('(','').replace(')','')\n",
    "    s2 = s1[1].split('+')\n",
    "    for r in s2:\n",
    "        meth_dat = pd.concat([meth_dat, pd.DataFrame({'Narrower':[r.strip()], 'Main':[s1[0].strip()], 'Main Label':[lab]})], sort=False)\n",
    "    return meth_dat\n",
    "\n",
    "\n",
    "def one_equals_others_minus_some(descr, lab):\n",
    "    #### D5A = D5 - (BR + CA + CN + IN + JP + RU + CH +US)\n",
    "    #meth_dat = pd.DataFrame(columns=['Narrower', 'Main'])\n",
    "    s1 = frame.split('=',1)\n",
    "    meth_dat = pd.DataFrame({'Narrower':['None'], 'Main':[s1[0].strip()], 'Main Label':[lab]})\n",
    "    return meth_dat\n",
    "\n",
    "\n",
    "def one_equals_one_and_minus_another(descr, lab):\n",
    "    #### Example = A3X=A3-MX\n",
    "    s1 = frame.split('=',1)\n",
    "    meth_dat = pd.DataFrame({'Narrower':['None'], 'Main':[s1[0].strip()], 'Main Label':[lab]})\n",
    "    return meth_dat\n",
    "\n",
    "\n",
    "def no_description(fram, lab, desc):   \n",
    "    return pd.DataFrame({'Narrower':['None'], 'Main':[fram.strip()], 'Main Label':[lab.strip()]})\n",
    "\n",
    "\n",
    "def all_pluses_in_description(descr, lab, fram):\n",
    "    #### Example = AG + BB + BS + BZ + CU + DM + DO + GD + GY + HT + JM + KN + LC + SR + TT + VC\n",
    "    meth_dat = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "    s1 = descr.split('+')\n",
    "    for r in s1:\n",
    "        r = r.replace('(','')\n",
    "        meth_dat = pd.concat([meth_dat, pd.DataFrame({'Narrower':[r.strip()], 'Main':[fram.strip()], 'Main Label':[lab]})], sort=False)\n",
    "    return meth_dat\n",
    "\n",
    "\n",
    "def until_or_from_in_description(fram, lab, descr):\n",
    "    return no_description(fram, lab, descr)\n",
    "\n",
    "\n",
    "def all_minuses_in_description(fram, lab, descr):\n",
    "    return no_description(fram, lab, descr)\n",
    "\n",
    "\n",
    "def descr_has_from_until_upto(fram, lab, descr):\n",
    "    now = datetime.datetime.now()\n",
    "    yr = now.year\n",
    "    addTo = False    \n",
    "    unfro = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "    if '=' in desc:\n",
    "        descr = descr.split('=',1)\n",
    "        descr = descr[1]\n",
    "    if '+' in descr:\n",
    "        s1 = descr.split('+')\n",
    "\n",
    "        for s in s1:\n",
    "            if 'from' in s.lower():\n",
    "                num = int((re.findall('\\d+', s))[0])\n",
    "                if num <= yr:\n",
    "                    s = ((s.split('(',1))[0]).strip()\n",
    "                    addTo = True\n",
    "                else:\n",
    "                    addTo = False\n",
    "            elif 'until' in s.lower():\n",
    "                num = int((re.findall('\\d+', s))[0])\n",
    "                if num >= yr:\n",
    "                    s = ((s.split('(',1))[0]).strip()\n",
    "                    addTo = True\n",
    "                else:\n",
    "                    addTo = False\n",
    "            elif 'up to' in s.lower():\n",
    "                num = int((re.findall('\\d+', s))[0])\n",
    "                if num >= yr:\n",
    "                    s = ((s.split('(',1))[0]).strip()\n",
    "                    addTo = True\n",
    "                else:\n",
    "                    addTo = False\n",
    "            else:\n",
    "                addTo = True\n",
    "                \n",
    "            if addTo:\n",
    "                unfro = pd.concat([unfro, pd.DataFrame({'Narrower':[s.strip()],'Main':[fram.strip()],\n",
    "                                'Main Label':[labe.strip()]})],sort=False)\n",
    "    else:\n",
    "        #print('Ignoring: ' + fram + ' === ' + desc)\n",
    "        unfro = pd.concat([unfro, pd.DataFrame({'Narrower':[''],'Main':[fram.strip()],\n",
    "                                'Main Label':[lab.strip()]})],sort=False)\n",
    "        \n",
    "    return unfro\n",
    "\n",
    "\n",
    "def another_special_case(fram, lab, descr):\n",
    "    # Descriptions with 'Country aggregate' or 'Candidate countries' in it\n",
    "    agg = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "    s1 = descr.split(' (' , 1)\n",
    "    s1[1] = s1[1].replace(')','')\n",
    "    if '+' in s1[1]:\n",
    "        s2 = s1[1].split('+')\n",
    "    else:\n",
    "        s2 = s1[1].split(',')\n",
    "    for c in s2:\n",
    "        agg = pd.concat([agg, pd.DataFrame({'Narrower':[c.strip()],'Main':[fram.strip()],\n",
    "                        'Main Label':[lab.strip()]})],sort=False)\n",
    "    \n",
    "    return agg\n",
    "\n",
    "def get_coordinates():\n",
    "    with open('Dev Code/geo-countries_zip/archive/countries.geojson') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    data = data[\"features\"]\n",
    "\n",
    "    co_dat = pd.DataFrame(columns=['Main Label', 'ISO', 'Shape', 'Coordinates'])\n",
    "    for x in data:\n",
    "        country = str(x['properties']['ADMIN']).strip()\n",
    "        iso = str(x['properties']['ISO_A3']).strip()\n",
    "        tpe = str(x['geometry']['type']).strip()\n",
    "        coord = str(x['geometry']['coordinates'])\n",
    "        coord = coord.replace('[','(')\n",
    "        coord = coord.replace(']',')')\n",
    "        # Each individual coordinate (2 numbers) has a bracket around it, which i don't think is needed compared to statistics.data.gov.uk\n",
    "        # e.g. http://statistics.data.gov.uk/resource.ttl?uri=http%3A%2F%2Fstatistics.data.gov.uk%2Fid%2Fstatistical-geography%2FW92000004%2Fgeometry\n",
    "        coord = coord.replace('(((','((') # Reduce all instances of 3 brackets down to 2\n",
    "        coord = coord.replace(')))','))')\n",
    "        coord = coord.replace(')), ((',')),--((') # Multipolygon, temp so its not deleted by the next line of code\n",
    "        coord = coord.replace('), (',', ') # Get rid of all end and start brackets inbetween coodinates\n",
    "        coord = coord.replace(')),--((',')), ((') # Change back the temp change\n",
    "        \n",
    "        co_dat = pd.concat([co_dat, pd.DataFrame({'Main Label':[country], 'ISO':[iso], 'Shape':[tpe], 'Coordinates':[coord]})], sort=False)\n",
    "    \n",
    "    return co_dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "dat2 = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "dat3 = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "dat4 = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "dat5 = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "dat6 = pd.DataFrame(columns=['Narrower', 'Main', 'Main Label'])\n",
    "\n",
    "for item, frame in are['Notation'].iteritems():\n",
    "    desc = str((list(are['Description'][are['Notation'] == frame]))[0])\n",
    "    labe = str((list(are['Label'][are['Notation'] == frame]))[0])\n",
    "    desc = desc.strip().replace('  ', ' ')     \n",
    "    if (('aggregate' in labe.lower()) or ('candidate' in labe.lower())) and (frame != 'C0'):\n",
    "        desc = 'special case'\n",
    "            \n",
    "    if (frame != 'A2A39') and (desc != 'nan'):\n",
    "        desc = desc.replace('W1=sum of all the (ISO 3166-1 alpha-2) partner countries +1A+W19;','')\n",
    "        desc = desc.replace('sum of (ISO 3166-1 alpha-2) partner countries;','')\n",
    "        desc = desc.replace('…','')\n",
    "        desc = desc.replace('+…','')\n",
    "        desc = desc.replace('(36 countries)','')\n",
    "        desc = desc.replace('+ A35E9','') # Need to look into this as A35E9 is not in Notations\n",
    "        desc = desc.replace('rule 1: ','')\n",
    "        desc = desc.replace('+ T F+','+ TF +')\n",
    "        if ('countries' in desc):\n",
    "            for x in range(90):\n",
    "                desc = desc.replace(f'({x} countries)','')  \n",
    "\n",
    "        if 'special case' in desc:\n",
    "            desc = labe\n",
    "            new_dat = another_special_case(frame, labe, desc)\n",
    "            dat6 = pd.concat([dat6,new_dat], sort=False)\n",
    "        elif ('from' in desc.lower()) or ('until' in desc.lower()) or ('up to' in desc.lower()):\n",
    "            new_dat = descr_has_from_until_upto(frame, labe, desc)\n",
    "            dat6 = pd.concat([dat6,new_dat], sort=False)\n",
    "            del new_dat\n",
    "        elif ('=' in desc) and ('-' not in desc):\n",
    "            new_dat = one_thing_equals_other_things(desc, labe)\n",
    "            dat1 = pd.concat([dat1,new_dat], sort=False)\n",
    "            del new_dat\n",
    "        elif ('=' in desc) and ('-' in desc) and ('from' not in desc):\n",
    "            if ('(' in desc) and (')' in desc):\n",
    "                if ('=' in desc) and (('+ (' in desc) or ('+(' in desc)) and ('-' in desc):\n",
    "                    new_dat = one_equals_others_plus_some_minus_some(desc, labe)\n",
    "                    dat2 = pd.concat([dat2,new_dat], sort=False)\n",
    "                    del new_dat\n",
    "                elif ('=' in desc) and (('- (' in desc) or ('-(' in desc)) and ('+' in desc):\n",
    "                    new_dat = one_equals_others_minus_some(desc, labe)\n",
    "                    dat2 = pd.concat([dat2,new_dat], sort=False)\n",
    "                    del new_dat\n",
    "                else:\n",
    "                    print(frame + ' -- ' + desc)\n",
    "            elif ('=' in desc) and ('-' in desc):\n",
    "                new_dat = one_equals_one_and_minus_another(desc, labe)\n",
    "                dat2 = pd.concat([dat2,new_dat], sort=False)\n",
    "                del new_dat\n",
    "            else:\n",
    "                print(frame + ' -- ' + desc)\n",
    "        elif 'rule' in desc:\n",
    "            new_dat = no_description(frame, labe, desc)\n",
    "            dat3 = pd.concat([dat3,new_dat], sort=False)\n",
    "            del new_dat\n",
    "        elif ('-' not in desc) and ('(' not in desc):\n",
    "            new_dat = all_pluses_in_description(desc, labe, frame)\n",
    "            dat5 = pd.concat([dat5,new_dat], sort=False)\n",
    "            del new_dat\n",
    "        elif '+' in desc:\n",
    "            new_dat = all_pluses_in_description(desc, labe, frame)\n",
    "            dat5 = pd.concat([dat5,new_dat], sort=False)\n",
    "            del new_dat\n",
    "        else:\n",
    "            new_dat = all_minuses_in_description(frame, labe, desc)\n",
    "            dat3 = pd.concat([dat3,new_dat], sort=False)\n",
    "            del new_dat\n",
    "    else:\n",
    "        new_dat = no_description(frame, labe, '')\n",
    "        dat4 = pd.concat([dat4,new_dat], sort=False)\n",
    "        del new_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of codes: 879\n",
      "dat1 count: 878 - Unique: 34\n",
      "dat2 count: 25 - Unique: 14\n",
      "dat3 count: 22 - Unique: 22\n",
      "dat4 count: 691 - Unique: 691\n",
      "dat5 count: 1571 - Unique: 90\n",
      "dat6 count: 394 - Unique: 28\n",
      "Before dropping duplicates from maindat: 879\n",
      "How many Main codes have been processed: 879\n",
      "How many Narrower codes: 363\n",
      "=============================================================================\n",
      "Number of Main Codes after joining: 879\n",
      "Number of Narrower codes after joining: 363\n"
     ]
    }
   ],
   "source": [
    "print('Original number of codes: ' + str(len(are['Notation'].unique())))\n",
    "print('dat1 count: ' + str(dat1['Main'].count()) + ' - Unique: ' + str(len(dat1['Main'].unique())))\n",
    "print('dat2 count: ' + str(dat2['Main'].count()) + ' - Unique: ' + str(len(dat2['Main'].unique())))\n",
    "print('dat3 count: ' + str(dat3['Main'].count()) + ' - Unique: ' + str(len(dat3['Main'].unique())))\n",
    "print('dat4 count: ' + str(dat4['Main'].count()) + ' - Unique: ' + str(len(dat4['Main'].unique())))\n",
    "print('dat5 count: ' + str(dat5['Main'].count()) + ' - Unique: ' + str(len(dat5['Main'].unique())))\n",
    "print('dat6 count: ' + str(dat6['Main'].count()) + ' - Unique: ' + str(len(dat6['Main'].unique())))\n",
    "dat1 = dat1.drop_duplicates()\n",
    "dat2 = dat2.drop_duplicates()\n",
    "dat3 = dat3.drop_duplicates()\n",
    "dat4 = dat4.drop_duplicates()\n",
    "dat5 = dat5.drop_duplicates()\n",
    "dat6 = dat6.drop_duplicates()\n",
    "maindat = pd.concat([dat1, dat2, dat3, dat4, dat5, dat6])\n",
    "print('Before dropping duplicates from maindat: ' + str(len(maindat['Main'].unique())))\n",
    "maindat = maindat.drop_duplicates()\n",
    "print('How many Main codes have been processed: ' + str(len(maindat['Main'].unique())))\n",
    "print('How many Narrower codes: ' + str(len(maindat['Narrower'].unique())))\n",
    "# Merge on Main to get the description\n",
    "maindat3 = pd.merge(maindat, are, how='left', left_on=['Main'], right_on=['Notation'])\n",
    "maindat3 = maindat3.rename(columns={'Description':'Main Description'})\n",
    "maindat3 = maindat3[['Narrower','Main','Main Label','Main Description']]\n",
    "# Merge on Narrower to get the label and description\n",
    "maindat3 = pd.merge(maindat3, are, how='left', left_on=['Narrower'], right_on=['Notation'])\n",
    "maindat3 = maindat3.rename(columns={'Description':'Narrow Description', 'Label':'Narrow Label'})\n",
    "maindat3 = maindat3[['Narrow Description','Narrow Label','Narrower','Main','Main Label','Main Description']]\n",
    "print('=============================================================================')\n",
    "print('Number of Main Codes after joining: ' + str(len(maindat3['Main'].unique())))\n",
    "print('Number of Narrower codes after joining: ' + str(len(maindat3['Narrower'].unique())))\n",
    "maindat = maindat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dat1, dat2, dat3, dat4, dat5, dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set things to None rather than NaN cos i don't like NaNs\n",
    "for c in maindat.columns:\n",
    "    if (c != 'Main Description') and (c != 'Narrow Description'):\n",
    "        maindat[c][maindat[c].isna()] = 'None'\n",
    "        maindat[c][maindat[c] == ''] = 'None'\n",
    "    \n",
    "#maindat.to_csv(\"codeHierarchyhCheck.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notation</th>\n",
       "      <th>Main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Notation, Main]\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if all codes have been captured\n",
    "df = pd.merge(are, maindat, how='left', left_on='Notation', right_on='Main')\n",
    "df = df[['Notation','Main']]\n",
    "d = df[df['Main'].isna()]\n",
    "# If nothing comes our of this then everything SHOULD be alright\n",
    "d.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Narrow Description</th>\n",
       "      <th>Narrow Label</th>\n",
       "      <th>Narrower</th>\n",
       "      <th>Main</th>\n",
       "      <th>Main Label</th>\n",
       "      <th>Main Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1B=1C+1D+1E+1F+1G+1H+1J+1K+1L+1M+1N+1O+1P+1Q+1...</td>\n",
       "      <td>UN organisations</td>\n",
       "      <td>1B</td>\n",
       "      <td>1A</td>\n",
       "      <td>International organisations</td>\n",
       "      <td>1A=1B+4A+4F+4S+5A+6A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4A=4B+4C+4D+4E+4G+4H+4I+4J+4M+4R+4T+4U+4V</td>\n",
       "      <td>All the European Union Institutions excluding ...</td>\n",
       "      <td>4A</td>\n",
       "      <td>1A</td>\n",
       "      <td>International organisations</td>\n",
       "      <td>1A=1B+4A+4F+4S+5A+6A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ECB (European Central Bank)</td>\n",
       "      <td>4F</td>\n",
       "      <td>1A</td>\n",
       "      <td>International organisations</td>\n",
       "      <td>1A=1B+4A+4F+4S+5A+6A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESM (European Stability Mechanism)</td>\n",
       "      <td>4S</td>\n",
       "      <td>1A</td>\n",
       "      <td>International organisations</td>\n",
       "      <td>1A=1B+4A+4F+4S+5A+6A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5AA+5B+…+5Z+7A+…7M</td>\n",
       "      <td>Other International Organisations (financial i...</td>\n",
       "      <td>5A</td>\n",
       "      <td>1A</td>\n",
       "      <td>International organisations</td>\n",
       "      <td>1A=1B+4A+4F+4S+5A+6A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6B+…+6Z</td>\n",
       "      <td>Other International Organisations (non-financi...</td>\n",
       "      <td>6A</td>\n",
       "      <td>1A</td>\n",
       "      <td>International organisations</td>\n",
       "      <td>1A=1B+4A+4F+4S+5A+6A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Narrow Description  \\\n",
       "0  1B=1C+1D+1E+1F+1G+1H+1J+1K+1L+1M+1N+1O+1P+1Q+1...   \n",
       "1          4A=4B+4C+4D+4E+4G+4H+4I+4J+4M+4R+4T+4U+4V   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                 5AA+5B+…+5Z+7A+…7M   \n",
       "5                                            6B+…+6Z   \n",
       "\n",
       "                                        Narrow Label Narrower Main  \\\n",
       "0                                   UN organisations       1B   1A   \n",
       "1  All the European Union Institutions excluding ...       4A   1A   \n",
       "2                        ECB (European Central Bank)       4F   1A   \n",
       "3                 ESM (European Stability Mechanism)       4S   1A   \n",
       "4  Other International Organisations (financial i...       5A   1A   \n",
       "5  Other International Organisations (non-financi...       6A   1A   \n",
       "\n",
       "                    Main Label      Main Description  \n",
       "0  International organisations  1A=1B+4A+4F+4S+5A+6A  \n",
       "1  International organisations  1A=1B+4A+4F+4S+5A+6A  \n",
       "2  International organisations  1A=1B+4A+4F+4S+5A+6A  \n",
       "3  International organisations  1A=1B+4A+4F+4S+5A+6A  \n",
       "4  International organisations  1A=1B+4A+4F+4S+5A+6A  \n",
       "5  International organisations  1A=1B+4A+4F+4S+5A+6A  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueCodes = maindat['Main'].unique()\n",
    "maindat.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCoordsWithMainData = True\n",
    "\n",
    "if mergeCoordsWithMainData == True:\n",
    "    \n",
    "    # Get all values from the coordinate files\n",
    "    coords = get_coordinates()\n",
    "    coords['Orig Label'] = coords['Main Label']\n",
    "    coords['Orig Label2'] = coords['Main Label']\n",
    "    \n",
    "    coords['Main Label'] = coords['Main Label'].str.strip()\n",
    "    # Got to rename some stuff to match up the two codelists\n",
    "    co = { \"The Bahamas\":\"Bahamas\",\n",
    "        \"Brunei\":\"Brunei Darussalam\",\n",
    "        \"Democratic Republic of the Congo\":\"Congo, the Democratic Republic of the\",\n",
    "        \"Republic of Congo\":\"Congo\",\n",
    "        \"Curaçao\":\"Curacao\",\n",
    "        \"Falkland Islands\":\"Falkland Islands (Malvinas)\",\n",
    "        \"Federated States of Micronesia\":\"Micronesia, Federated States of\",\n",
    "        \"Guinea Bissau\":\"Guinea-Bissau\",\n",
    "        \"Hong Kong S.A.R.\":\"Hong Kong, China\",\n",
    "        \"British Indian Ocean Territory\":\"British Indian Ocean territory\",\n",
    "        \"Iran\":\"Iran, Islamic Republic of\",\n",
    "        \"South Korea\":\"Korea, Republic of\",\n",
    "        \"Laos\":\"Lao People`s Democratic Republic\",\n",
    "        \"Macao S.A.R\":\"Macao\",\n",
    "        \"Saint Martin\":\"Saint Martin (French part)\",\n",
    "        \"Moldova\":\"Moldova, Republic of\",\n",
    "        \"Macedonia\":\"Republic of North Macedonia\",\n",
    "        \"Pitcairn Islands\":\"Pitcairn\",\n",
    "        \"North Korea\":\"Korea, Democratic People`s Republic of\",\n",
    "        \"Palestine\":\"Palestine, State of\",\n",
    "        \"Russia\":\"Russian Federation\",\n",
    "        \"South Georgia and South Sandwich Islands\":\"South Georgia and the South Sandwich Islands\",\n",
    "        \"Republic of Serbia\":\"Serbia\",\n",
    "        \"Sint Maarten\":\"Sint Maarten (Dutch part)\",\n",
    "        \"Syria\":\"Syrian Arab Republic\",\n",
    "        \"East Timor\":\"Timor-Leste\",\n",
    "        \"Taiwan\":\"Taiwan, Province of China\",\n",
    "        \"United Republic of Tanzania\":\"Tanzania, United Republic of\",\n",
    "        \"United States Minor Outlying Islands\":\"United States Minor outlying islands\",\n",
    "        \"United States of America\":\"United States\",\n",
    "        \"Vatican\":\"Holy See (Vatican City State)\",\n",
    "        \"Venezuela\":\"Venezuela, Bolivarian Republic\",\n",
    "        \"British Virgin Islands\":\"Virgin Islands, British\",\n",
    "        \"United States Virgin Islands\":\"Virgin Islands, U.S.\",\n",
    "        \"Vietnam\":\"Viet Nam\"\n",
    "    }\n",
    "\n",
    "    for key in co:\n",
    "        coords['Orig Label'][coords['Main Label'] == key] = co[key]\n",
    "        coords['Main Label'][coords['Main Label'] == key] = co[key]\n",
    "\n",
    "        \n",
    "    maindat = pd.merge(maindat,coords, on='Main Label', how='left')\n",
    "    coords2 = pd.merge(coords,maindat, on='Orig Label2', how='left')\n",
    "\n",
    "    maindat['ISO'][maindat['ISO'].isna()] = 'None'\n",
    "    maindat['ISO'][maindat['ISO'] == '-99'] = 'None'\n",
    "    maindat['Coordinates'][maindat['Coordinates'].isna()] = 'None'\n",
    "    maindat['Shape'][maindat['Shape'].isna()] = 'None'\n",
    "    \n",
    "    # Check which country coordinates are missing, should be 21 left that are not in the main codelist\n",
    "    mainCnt = pd.DataFrame(list(maindat['ISO'].unique()))\n",
    "    mainCnt = mainCnt.rename(columns={0:\"ISO\"})\n",
    "\n",
    "    mainCnt = mainCnt.merge(maindat, on='ISO', how='left')\n",
    "    mainCnt = mainCnt[['ISO','Main Label']]\n",
    "    mainCnt = mainCnt[mainCnt['ISO'] != 'None']\n",
    "    mainCnt = list(mainCnt['Main Label'])\n",
    "\n",
    "    cordCnt = list(coords['Main Label'])\n",
    "\n",
    "    co_not = pd.DataFrame(columns=['Main Label'])\n",
    "    co_in = pd.DataFrame(columns=['Main Label'])\n",
    "\n",
    "    for c in cordCnt:\n",
    "        if c not in mainCnt:     \n",
    "            co_not = pd.concat([co_not, pd.DataFrame({'Main Label':[c]})], sort=False)\n",
    "        else:\n",
    "            co_in = pd.concat([co_in, pd.DataFrame({'Main Label':[c]})], sort=False)\n",
    "\n",
    "\n",
    "    #co_dat.to_csv('missing_countries.csv')\n",
    "    co_in.to_csv('countries_with_coords.csv', index=False)\n",
    "    pd.DataFrame(co_not).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main Label</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Coords</th>\n",
       "      <th>Orig Label1</th>\n",
       "      <th>Main</th>\n",
       "      <th>Orig Label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Iran, Islamic Republic of</td>\n",
       "      <td>IRN</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>(((55.054372592000306, 25.864610092999968, 55....</td>\n",
       "      <td>Iran, Islamic Republic of</td>\n",
       "      <td>IR</td>\n",
       "      <td>Iran</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Main Label  ISO         Shape  \\\n",
       "108  Iran, Islamic Republic of  IRN  MultiPolygon   \n",
       "\n",
       "                                                Coords  \\\n",
       "108  (((55.054372592000306, 25.864610092999968, 55....   \n",
       "\n",
       "                   Orig Label1 Main Orig Label2  \n",
       "108  Iran, Islamic Republic of   IR        Iran  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords2 = coords2[['Main Label_x', 'ISO_x', 'Shape_x', 'Coordinates_x', 'Orig Label_x', 'Main', 'Orig Label2']]\n",
    "coords2 = coords2.rename(columns={'Orig Label_x':'Orig Label1', 'Main Label_x':'Main Label', 'ISO_x':'ISO','Shape_x':'Shape','Coordinates_x':'Coords'})\n",
    "coords2 = coords2[~coords2['Main'].isna()]\n",
    "\n",
    "#coords2[coords2['Main Label'].str.contains('Congo')]\n",
    "coords2[coords2['Main Label'].str.contains('Iran')]\n",
    "#coords2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Country and Institution Triples\n",
    "g = Graph()\n",
    "repoBase = \"http://gss-data.org.uk/def\"\n",
    "con = \"concept\"\n",
    "sch = \"scheme\"\n",
    "consch = con + \"-\" + sch\n",
    "sortPri = 'http://www.w3.org/ns/ui#sortPriority'\n",
    "\n",
    "mainLabel = \"SDMX Area codelist\"\n",
    "main =\"hierarchical-codelist-sdmx-area\"\n",
    "desc = \"Dataset representing the SDMX Area codelist with added Geometry. URN: urn:sdmx:org.sdmx.infomodel.codelist.Codelist=IMF:CL_AREA(1.13). Main source: https://sdmx.org/?page_id=1747. Structure source: https://registry.sdmx.org/ws/public/sdmxapi/rest/datastructure/IMF/BOP/1.14/?detail=full&references=descendants&version=2.1:1:555:. \"\n",
    "if mergeCoordsWithMainData == True:\n",
    "    desc = desc + \"Geometry source data: https://datahub.io/core/geo-countries#resource-geo-countries_zip.\"\n",
    "    \n",
    "geomURI = URIRef('http://www.opengis.net/ont/geosparql#Geometry')\n",
    "geomSpa = URIRef('http://www.opengis.net/ont/geosparql#asWKT')\n",
    "hasGeom = URIRef('http://www.opengis.net/ont/geosparql#hasGeometry')\n",
    "\n",
    "schemeURI = URIRef(repoBase + \"/\" + con + '-' + sch + \"/\" + main)\n",
    "i = 1\n",
    "\n",
    "datasetStr = '/dataset'\n",
    "catrecStr = '/catalog-record'\n",
    "\n",
    "# Set up the main schema triples\n",
    "\n",
    "g.add((schemeURI, RDF.type, SKOS.ConceptScheme))\n",
    "g.add((schemeURI, RDF.type, URIRef(\"http://publishmydata.com/pmdcat#ConceptScheme\")))\n",
    "g.add((schemeURI, URIRef(\"http://purl.org/dc/terms/title\"), Literal(mainLabel, lang=\"en\")))\n",
    "g.add((schemeURI, RDFS.label, Literal(mainLabel, lang=\"en\")))\n",
    "g.add((schemeURI, RDFS.seeAlso, URIRef(schemeURI + datasetStr)))\n",
    "g.add((schemeURI, URIRef(\"http://www.w3.org/ns/prov#hadDerivation\"), URIRef(schemeURI)))\n",
    "g.add((schemeURI, URIRef(\"http://gss-data.org.uk/catalog/vocabularies\"), URIRef(schemeURI + catrecStr)))\n",
    "\n",
    "#g.add((URIRef(schemeURI + datasetStr), RDF.type, URIRef(\"http://publishmydata.com/pmdcat#Dataset\")))\n",
    "\n",
    "#datasetDateTime = \"2021-03-04T11:40:13Z\"\n",
    "#g.add((URIRef(schemeURI + datasetStr), RDF.type, URIRef(\"http://www.w3.org/ns/dcat#Dataset\")))\n",
    "#g.add((URIRef(schemeURI + datasetStr), URIRef(\"http://purl.org/dc/terms/modified\"), Literal(datasetDateTime, datatype=XSD.dateTime)))\n",
    "#g.add((URIRef(schemeURI + datasetStr), URIRef(\"http://publishmydata.com/pmdcat#graph\"), URIRef(schemeURI)))\n",
    "#g.add((URIRef(schemeURI + datasetStr), URIRef(\"http://purl.org/dc/terms/issued\"), Literal(datasetDateTime, datatype=XSD.dateTime)))\n",
    "#g.add((URIRef(schemeURI + datasetStr), RDFS.label, Literal(mainLabel)))\n",
    "#g.add((URIRef(schemeURI + datasetStr), URIRef(\"http://publishmydata.com/pmdcat#datasetContents\"), URIRef(schemeURI)))\n",
    "#g.add((URIRef(schemeURI + datasetStr), RDFS.comment, Literal(desc, lang=\"en\")))\n",
    "#g.add((URIRef(schemeURI + datasetStr), URIRef(\"http://purl.org/dc/terms/title\"), Literal(mainLabel)))\n",
    "\n",
    "#g.add((URIRef(\"http://gss-data.org.uk/catalog/vocabularies\"), URIRef(\"http://www.w3.org/ns/dcat#record\"), URIRef(schemeURI + catrecStr)))\n",
    "\n",
    "#catRecDateTime = \"2020-12-23T11:58:58.120533\"\n",
    "#g.add((URIRef(schemeURI + catrecStr), RDF.type, URIRef(\"http://www.w3.org/ns/dcat#CatalogRecord\")))\n",
    "#g.add((URIRef(schemeURI + catrecStr), URIRef(\"http://purl.org/dc/terms/title\"), Literal(mainLabel, lang=\"en\")))\n",
    "#g.add((URIRef(schemeURI + catrecStr), URIRef(\"http://purl.org/dc/terms/issued\"), Literal(catRecDateTime, datatype=XSD.dateTime)))\n",
    "#g.add((URIRef(schemeURI + catrecStr), URIRef(\"http://xmlns.com/foaf/0.1/primaryTopic\"), URIRef(schemeURI + datasetStr)))\n",
    "#g.add((URIRef(schemeURI + catrecStr), URIRef(\"http://purl.org/dc/terms/modified\"), Literal(catRecDateTime, datatype=XSD.dateTime)))\n",
    "#g.add((URIRef(schemeURI + catrecStr), URIRef(\"http://publishmydata.com/pmdcat#metadataGraph\"), URIRef(schemeURI)))\n",
    "\n",
    "\n",
    "addMainData = True\n",
    "if addMainData == True:\n",
    "    for row in maindat.iterrows():\n",
    "        if 'None' not in row[1]['Main']:\n",
    "            conceptURI = URIRef(repoBase + \"/\" + con + \"/\" + main + \"/\" + str(pathify(row[1]['Main'])).upper())\n",
    "            g.add((conceptURI, RDF.type, SKOS.Concept))\n",
    "            g.add((conceptURI, RDFS.label, Literal(row[1]['Main Label'], lang=\"en\")))\n",
    "            g.add((conceptURI, SKOS.prefLabel, Literal(row[1]['Main Label'], lang=\"en\")))\n",
    "            g.add((conceptURI, SKOS.altLabel, Literal(row[1]['Main Label'] + \" - \" + row[1]['Main'], lang=\"en\")))\n",
    "            g.add((conceptURI, SKOS.inScheme, URIRef(schemeURI)))\n",
    "            g.add((conceptURI, SKOS.notation, Literal(str(pathify(row[1]['Main'])).upper())))\n",
    "            #### GEOMETRY\n",
    "            #mergeCoordsWithMainData = False\n",
    "            if mergeCoordsWithMainData == True:\n",
    "                if 'None' not in row[1]['Coordinates']:\n",
    "                    conceptGeom = URIRef(repoBase + \"/\" + con + \"/\" + main + \"/\" + str(pathify(row[1]['Main'])).upper() + '/geometry')\n",
    "                    g.add((conceptURI, hasGeom, conceptGeom))\n",
    "            if 'None' not in row[1]['Narrower']:\n",
    "                broaderURI = URIRef(repoBase + \"/\" + con + \"/\" + main + \"/\" + str(pathify(row[1]['Narrower']).upper()))\n",
    "                g.add((conceptURI, SKOS.Narrower, broaderURI))\n",
    "            try:\n",
    "                if 'None' not in row[1]['Main Description']:\n",
    "                    g.add((conceptURI, RDFS.comment, Literal(row[1]['Main Description'], lang=\"en\")))\n",
    "            except:\n",
    "                #print(row[1]['Main Description'])\n",
    "                i = 0\n",
    "    #        #g.add((conceptURI, URIRef(sortPri), Literal(i)))\n",
    "    #        i = i + 1   \n",
    "        if 'None' not in row[1]['Narrower']:\n",
    "            conceptURI = URIRef(repoBase + \"/\" + con + \"/\" + main + \"/\" + str(pathify(row[1]['Narrower'])).upper())\n",
    "            g.add((conceptURI, RDF.type, SKOS.Concept))\n",
    "            g.add((conceptURI, RDFS.label, Literal(row[1]['Narrow Label'], lang=\"en\")))\n",
    "            g.add((conceptURI, SKOS.prefLabel, Literal(row[1]['Narrow Label'], lang=\"en\")))\n",
    "            g.add((conceptURI, SKOS.altLabel, Literal(row[1]['Narrow Label'] + \" - \" + row[1]['Narrower'], lang=\"en\")))\n",
    "            g.add((conceptURI, SKOS.inScheme, URIRef(schemeURI)))\n",
    "            g.add((conceptURI, SKOS.notation, Literal(str(pathify(row[1]['Narrower'])).upper())))\n",
    "            if 'None' not in row[1]['Main']:\n",
    "                broaderURI = URIRef(repoBase + \"/\" + con + \"/\" + main + \"/\" + str(pathify(row[1]['Main']).upper()))\n",
    "                g.add((conceptURI, SKOS.broader, broaderURI))\n",
    "            try:\n",
    "                if 'None' not in row[1]['Narrow Description']:\n",
    "                    g.add((conceptURI, RDFS.comment, Literal(row[1]['Narrow Description'], lang=\"en\")))\n",
    "            except:\n",
    "                #print(row[1]['Narrow Description'])\n",
    "                i = 0\n",
    "            #g.add((conceptURI, URIRef(sortPri), Literal(i)))\n",
    "            i = i + 1\n",
    "        #break\n",
    "        \n",
    "    schemeURI = URIRef(repoBase + \"/\" + con + '-' + sch + \"/\" + main)\n",
    "    #print(schemeURI)\n",
    "    \n",
    "    i = 0\n",
    "    for c in uniqueCodes:   \n",
    "        conceptURI = URIRef(repoBase + \"/\" + con + \"/\" + main + \"/\" + c)\n",
    "        g.add((URIRef(schemeURI), SKOS.hasTopConcept, URIRef(conceptURI)))\n",
    "        i = i + 1\n",
    "        #if i == 2:\n",
    "            #break\n",
    "\n",
    "#g.bind(\"cogs\", URIRef(\"http://gss-data.org.uk/def/concept/sdmx_area/\"))\n",
    "g.bind(\"skos\", SKOS)\n",
    "g.bind(\"rdf\", RDF)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"dc\", URIRef(\"http://purl.org/dc/terms/\"))\n",
    "g.bind(\"prov\", URIRef(\"http://www.w3.org/ns/prov#\"))\n",
    "g.bind(\"vocab\", URIRef(\"http://gss-data.org.uk/catalog/\"))\n",
    "g.bind(\"pmdcat\", URIRef(\"http://publishmydata.com/pmdcat#\"))\n",
    "g.bind(\"dcat\", URIRef(\"http://www.w3.org/ns/dcat#\"))\n",
    "g.bind(\"foaf\", URIRef(\"http://xmlns.com/foaf/0.1/\"))\n",
    "g.bind(\"geo\", URIRef(\"http://www.opengis.net/ont/geosparql#\"))\n",
    "\n",
    "#print(g.serialize(format='n3').decode(\"utf-8\"))\n",
    "\n",
    "g.serialize(destination='ref_common/reference/bop-sdmx-codelists/cl-area.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main Label</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Coords</th>\n",
       "      <th>Orig Label1</th>\n",
       "      <th>Main</th>\n",
       "      <th>Orig Label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>((-69.99693762899992, 12.577582098000036, -69....</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>AW</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Main Label  ISO    Shape                                             Coords  \\\n",
       "0      Aruba  ABW  Polygon  ((-69.99693762899992, 12.577582098000036, -69....   \n",
       "\n",
       "  Orig Label1 Main Orig Label2  \n",
       "0       Aruba   AW       Aruba  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "# Geometry Triples\n",
    "ggeom = Graph()\n",
    "\n",
    "datasetStr = '/dataset'\n",
    "catrecStr = '/catalog-record'\n",
    "\n",
    "geomCogsURI = URIRef(repoBase + \"/\" + con + '-' + sch + \"/codelist-geometry\")\n",
    "geomLabel = \"Country geometry data (polygons)\"\n",
    "\n",
    "ggeom.add((geomCogsURI, RDF.type, SKOS.ConceptScheme))\n",
    "ggeom.add((geomCogsURI, RDF.type, URIRef(\"http://publishmydata.com/pmdcat#ConceptScheme\")))\n",
    "ggeom.add((geomCogsURI, URIRef(\"http://purl.org/dc/terms/title\"), Literal(geomLabel, lang=\"en\")))\n",
    "ggeom.add((geomCogsURI, RDFS.label, Literal(geomLabel, lang=\"en\")))\n",
    "ggeom.add((geomCogsURI, RDFS.seeAlso, URIRef(geomCogsURI + datasetStr)))\n",
    "ggeom.add((geomCogsURI, URIRef(\"http://www.w3.org/ns/prov#hadDerivation\"), URIRef(geomCogsURI)))\n",
    "ggeom.add((geomCogsURI, URIRef(\"http://gss-data.org.uk/catalog/vocabularies\"), URIRef(geomCogsURI + catrecStr)))\n",
    "i = 0\n",
    "#'Main Label', 'ISO', 'Shape', 'Coords', 'Orig Label_x', 'Main'\n",
    "for row in coords2.iterrows():\n",
    "    if 'None' not in row[1]['Main']:\n",
    "        conceptGeom = URIRef(repoBase + \"/\" + con + \"/\" + main + \"/\" + str(pathify(row[1]['Main'])).upper() + '/geometry')\n",
    "        ggeom.add((conceptGeom, RDF.type, SKOS.Concept))\n",
    "        ggeom.add((conceptGeom, RDFS.label, Literal(row[1]['Main Label'], lang=\"en\")))\n",
    "        ggeom.add((conceptGeom, SKOS.prefLabel, Literal(row[1]['Main Label'], lang=\"en\")))\n",
    "        ggeom.add((conceptGeom, SKOS.altLabel, Literal(row[1]['Orig Label2'] + ' - ' + row[1]['ISO'], lang=\"en\")))\n",
    "        ggeom.add((conceptGeom, SKOS.inScheme, URIRef(geomCogsURI)))\n",
    "        ggeom.add((conceptGeom, RDF.type, geomURI))\n",
    "        ggeom.add((conceptGeom, SKOS.notation, Literal(str(pathify(row[1]['Main'])).upper())))\n",
    "        geomCoords = Literal(row[1]['Shape'].upper() + ' ' + str(row[1]['Coords']), datatype=URIRef(\"http://www.opengis.net/ont/geosparql#wktLiteral\"))\n",
    "        ggeom.add((conceptGeom, geomSpa, geomCoords))  \n",
    "    i = i + 1\n",
    "            \n",
    "print(i) \n",
    "ggeom.bind(\"skos\", SKOS)\n",
    "ggeom.bind(\"geo\", URIRef(\"http://www.opengis.net/ont/geosparql#\"))\n",
    "ggeom.bind(\"prov\", URIRef(\"http://www.w3.org/ns/prov#\"))\n",
    "ggeom.bind(\"dc\", URIRef(\"http://purl.org/dc/terms/\"))\n",
    "ggeom.bind(\"vocab\", URIRef(\"http://gss-data.org.uk/catalog/\"))\n",
    "\n",
    "ggeom.serialize(destination='ref_common/reference/bop-sdmx-codelists/cl-geometry.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 6 10 13 22 44\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print(now.year, now.month, now.day, now.hour, now.minute, now.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitb3249c1df48246aabe11cf3e801b18c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
